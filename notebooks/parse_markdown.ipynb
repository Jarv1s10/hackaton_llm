{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import yaml\n",
    "from markdown import Markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r\"\\d+ min read(?: - updated few hours ago)?\")\n",
    "regex.sub('', '3 min read - updated few hours ago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_json(text: str):\n",
    "    print(json.dumps(text, indent=4))\n",
    "\n",
    "def delete_html_tags(text):\n",
    "    tag_regex = re.compile(r'<.*?>')\n",
    "    t = re.sub(tag_regex, ' ', text)\n",
    "    t = ' '.join([s for s in t.split(' ') if s])\n",
    "    return t\n",
    "\n",
    "def delete_html_comments(text):\n",
    "    comment_regex = re.compile(r'<!--((.|\\n)*?)-->', re.MULTILINE)\n",
    "    t = re.sub(comment_regex, ' ', text)\n",
    "    t = ' '.join([s for s in t.split(' ') if s])\n",
    "    return t\n",
    "\n",
    "def get_text_from_md_link(text):\n",
    "    url_regex = re.compile(r'__|\\*|\\#|(?:\\[([^\\]]*)\\]\\([^)]*\\))')\n",
    "    return re.sub(url_regex, r'\\1', text)\n",
    "\n",
    "def clear_text(text):\n",
    "    t = delete_html_tags(t)\n",
    "    t = delete_html_comments(t)\n",
    "    t = get_text_from_md_link(t)\n",
    "    t = '\\n'.join([s.strip() for s in t.split('\\n') if s.strip()])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../preprocessed_data/docs_objects.json') as f:\n",
    "    docs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(docs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = []\n",
    "for doc in tqdm(docs):\n",
    "    tokenized_docs.append(encoding.encode(doc['text_content']))\n",
    "token_lengths = list(map(len, tokenized_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = random.choice(docs)\n",
    "doc = [doc for doc in docs if doc['doc_url'] == 'https://docs.revenuegrid.com/ri/fast/articles/Frequently-Asked-Questions'][0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(Markdown(output_format='html').convert(doc['full_content']))\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_doc_by_sections(doc: dict):\n",
    "    doc_sections = []\n",
    "    soup = BeautifulSoup(Markdown(output_format='html').convert(doc['full_content']))\n",
    "    header_regex = re.compile(r'h\\d')\n",
    "    for el in soup.find('body'):\n",
    "        if el.name is None or not re.fullmatch(header_regex, el.name):\n",
    "            continue\n",
    "        sec_info = {'sec_level': int(el.name[-1]),\n",
    "                    'sec_title': el.text,\n",
    "                    'sec_text': ''}\n",
    "        for sib in el.next_siblings:\n",
    "            if sib.name is not None and re.fullmatch(header_regex, sib.name):\n",
    "                break\n",
    "            if not sib.text.strip() or sib.name in ('style', 'comment', 'script'):\n",
    "                continue\n",
    "            sec_info['sec_text'] += sib.text.strip() + '\\n'\n",
    "        doc_sections.append(sec_info)\n",
    "    return doc_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [split_doc_by_sections(doc) for doc in docs]\n",
    "len(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([secs for secs in sections if secs[0]['sec_level'] == 2 and secs[0]['sec_text'] == ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(secs) > 1 and secs[1]['sec_level'] == 1 for secs in sections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[secs for secs in sections if len(secs) > 1 and secs[1]['sec_level'] == 1 and secs[0]['sec_level'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[secs for secs in sections if secs[0]['sec_level'] == 2 and secs[0]['sec_text'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([secs[0]['sec_level'] == 1 for secs in sections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "142+196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_first_h2_with_h1(sections: list):\n",
    "    h1_sec = sections[1]\n",
    "    h1_sec['sec_text'] = sections[0]['sec_text'] + '\\n' + h1_sec['sec_text']\n",
    "    sections[1] = h1_sec\n",
    "    return sections[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [merge_first_h2_with_h1(secs) if secs[0]['sec_level'] == 2 else secs for secs in sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([any([s['sec_text'] == '' for s in sec]) for sec in sections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([secs[0]['sec_level'] == 1 for secs in sections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(nodes):\n",
    "    root = {'children': []}\n",
    "    stack = [(root, 0)]\n",
    "\n",
    "    for node in nodes:\n",
    "        level = node['sec_level']\n",
    "        while stack[-1][1] >= level:\n",
    "            stack.pop()\n",
    "\n",
    "        parent = stack[-1][0]\n",
    "        child = {'sec_title': node['sec_title'], 'sec_text': node['sec_text'], 'children': []}\n",
    "        parent['children'].append(child)\n",
    "        stack.append((child, level))\n",
    "\n",
    "    return root['children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint_json(create_tree(sections[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nodes(tree, threshold):\n",
    "    if not tree or len(tree) == 0:\n",
    "        return None\n",
    "\n",
    "    # Recursively merge child nodes first\n",
    "    for node in tree:\n",
    "        node['children'] = merge_nodes(node['children'], threshold)\n",
    "\n",
    "    # Check if all children can be merged into one node\n",
    "    if len(tree) > 1:\n",
    "        all_same_level = all(node['sec_level'] == tree[0]['sec_level'] for node in tree)\n",
    "        all_mergeable = all(len(node['sec_text']) <= threshold for node in tree)\n",
    "        if all_same_level and all_mergeable:\n",
    "            merged_text = ' '.join(node['sec_text'] for node in tree)\n",
    "            merged_node = {\n",
    "                'sec_title': tree[0]['sec_title'],\n",
    "                'sec_text': merged_text,\n",
    "                'children': []\n",
    "            }\n",
    "            return [merged_node]\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdocs = []\n",
    "for doc in docs:\n",
    "    subdoc = {\n",
    "        'doc_title': doc['title'],\n",
    "        'site_name': doc['site_name'],\n",
    "        'short_site_name': doc['short_site_name'],\n",
    "        'doc_url': doc['doc_url'],\n",
    "        'doc_filepath': doc['doc_filepath'],\n",
    "        'nav_keys_list': doc['nav_keys_list']\n",
    "    }\n",
    "    if not doc['subtopics']:\n",
    "        subdoc['topic_title'] = doc['title']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
